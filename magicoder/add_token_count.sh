accelerate launch --main_process_port=8000 -m magicoder.add_token_count \
  --model_key "codellama/CodeLlama-7b-Python-hf" \
  --model_name_or_path "../wizardcoder_gpt4_40g" \
  --use_flash_attention True \
  --max_training_seq_length 1024 \
  --datafile_paths \
    "../magicoder_data/data-evol_instruct-decontaminated.jsonl" \
  --output_dir "../wizardcoder-with-codevol-instruct-0305" \
  --bf16 True \
  --num_train_epochs 2 \
  --per_device_train_batch_size 1 \
  --gradient_accumulation_steps 64 \
  --group_by_length False \
  --ddp_find_unused_parameters False \
  --logging_steps 1 \
  --log_level info \
  --optim adafactor \
  --max_grad_norm -1 \
  --warmup_steps 15 \
  --learning_rate 5e-5 \
  --lr_scheduler_type linear
